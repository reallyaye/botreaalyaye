# bot/handlers/ask_ai.py
import re
import os
import asyncio
from dotenv import load_dotenv

from aiogram import Router, F
from aiogram.types import Message
from aiogram.filters.state import StateFilter
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.context import FSMContext

from openai import OpenAI
from bot.keyboards import cancel_keyboard, main_menu

load_dotenv()

API_KEY = os.getenv("SAMBANOVA_API_KEY") or os.getenv("OPENAI_API_KEY")
if not API_KEY:
    raise RuntimeError("–ù—É–∂–Ω–æ –∑–∞–¥–∞—Ç—å SAMBANOVA_API_KEY –∏–ª–∏ OPENAI_API_KEY –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏")

client = OpenAI(
    api_key=API_KEY,
    base_url="https://api.sambanova.ai/v1"  # –∏–ª–∏ —É–±–µ—Ä–∏—Ç–µ, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –æ–±—ã—á–Ω—ã–π OpenAI
)

router = Router()

class AskAIState(StatesGroup):
    waiting_for_question = State()

@router.message(F.text == "ü§ñ –°–ø—Ä–æ—Å–∏—Ç—å —É –ò–ò")
async def ai_start(message: Message, state: FSMContext):
    # –æ—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é
    await state.clear()
    await state.update_data(
        history=[{"role": "system", "content": "You are a helpful assistant."}]
    )
    await message.answer(
        "üñä –í–≤–µ–¥–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–∞—à –≤–æ–ø—Ä–æ—Å –¥–ª—è –ò–ò:",
        reply_markup=cancel_keyboard
    )
    await state.set_state(AskAIState.waiting_for_question)

@router.message(StateFilter(AskAIState.waiting_for_question))
async def ai_handle(message: Message, state: FSMContext):
    text = message.text.strip()
    if text.lower() == "–æ—Ç–º–µ–Ω–∞":
        await state.clear()
        return await message.answer("‚ùå –î–∏–∞–ª–æ–≥ —Å –ò–ò –∑–∞–≤–µ—Ä—à–µ–Ω.", reply_markup=main_menu)

    # –¥–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
    data = await state.get_data()
    history = data.get("history", [])
    history.append({"role": "user", "content": text})

    await message.answer("üîé –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–∞—à –∑–∞–ø—Ä–æ—Å‚Ä¶")

    # –≤—ã–ø–æ–ª–Ω—è–µ–º –≤—ã–∑–æ–≤ –ò–ò –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    def ai_request():
        return client.chat.completions.create(
            model="DeepSeek-R1",       # –∏–ª–∏ "gpt-3.5-turbo"
            messages=history,
            temperature=0.1,
            top_p=0.1,
        )

    try:
        resp = await asyncio.to_thread(ai_request)
        raw_answer = resp.choices[0].message.content or ""
        # –≤—ã—Ä–µ–∑–∞–µ–º –≤—Å—ë –º–µ–∂–¥—É <think> –∏ </think> (–≤–∫–ª—é—á–∞—è —Ç–µ–≥–∏)
        clean_answer = re.sub(r'<think>.*?</think>', '', raw_answer, flags=re.DOTALL).strip()
    except Exception as e:
        clean_answer = f"‚ùó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ò–ò:\n{e}"

    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏–∏
    history.append({"role": "assistant", "content": clean_answer})
    await state.update_data(history=history)

    # –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —É–∂–µ –æ—á–∏—â–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –∏ –æ—Å—Ç–∞—ë–º—Å—è –≤ —Ç–æ–º –∂–µ —Å–æ—Å—Ç–æ—è–Ω–∏–∏
    await message.answer(clean_answer, reply_markup=cancel_keyboard)

# –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ö—ç–Ω–¥–ª–µ—Ä –Ω–∞ –∫–æ–º–∞–Ω–¥—É /cancel:
@router.message(F.text.lower() == "–æ—Ç–º–µ–Ω–∞", StateFilter(AskAIState.waiting_for_question))
async def ai_cancel(message: Message, state: FSMContext):
    await state.clear()
    await message.answer("‚ùå –î–∏–∞–ª–æ–≥ —Å –ò–ò –∑–∞–≤–µ—Ä—à–µ–Ω.", reply_markup=main_menu)
